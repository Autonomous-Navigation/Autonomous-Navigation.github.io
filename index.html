<!DOCTYPE html>
<html>
<head>
    <style>
        #moreInfo {
            display: none;
            border: 1px solid #ddd;
            border-collapse: collapse;
            margin: auto;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            background-color: #f9f9f9;
            padding: 20px;
            width: 850px;
        }

        .infoButton {
            display: block;
            width: 200px;
            padding: 10px;
            margin: 20px auto;
            background-color: #007bff;
            color: white;
            text-align: center;
            border-radius: 5px;
            cursor: pointer;
        }

        .infoButton:hover {
            background-color: #0056b3;
        }
	.toggleButton {
            display: block;
            width: 200px;
            padding: 10px;
            margin: 20px auto;
            background-color: #007bff;
            color: white;
            text-align: center;
            border-radius: 5px;
            cursor: pointer;
        }

        .toggleButton:hover {
            background-color: #0056b3;
        }

        .contentContainer {
            display: none;
        }    
    </style>
</head>
<body>
		<span style="font-size:36px">AGNI : Autonomous Ground Navigation Initiative</span>
		<table align="center" width="1000px">
			<tr>
				<td>
					<table align="center" width="1000px" cellspacing="5px">
						<tr>
							<td align="center" width="150px">
								<span style="font-size:20px"><a href="https://www.linkedin.com/in/arjun-sivakumar-2459701a0/" target="_blank">Arjun Sivakumar<sup>1</sup>*</a></span>
							</td>
							<td align="center" width="150px">
								<span style="font-size:20px"><a href="https://www.linkedin.com/in/bhumil-depani-779a32147/" target="_blank">Bhumil Depani<sup>1</sup>*</a></span>
							</td>
							<td align="center" width="150px">
								<span style="font-size:20px"><a href="https://www.linkedin.com/in/ricky-bevan-babu-290ba9190/" target="_blank">Ricky Bevan Babu<sup>1</sup>*</a></span>
							</td>
						</tr>
					</table>
				</td>
			</tr>
		</table>
		<table align="center" width="800px">
                <tr>
                    <td>
                        <center>
                            <img class="round" style="width:500px" src="files/css/image/Screenshot_20230524_115532_Gallery-removebg-preview.png"/>
                        </center>
			<center>
                            <img class="round" style="width:500px" src="files/css/image/team.jpg"/>
                        </center>    
                    </td>
                </tr>
            </table>

		<br>
	    <div class="toggleButton" onclick="toggleContent('motivationContent')">Toggle Motivation</div>

   
            <div id="motivationContent" class="contentContainer">

		

	<hr>
	 <table align="center" width="850px">
        <h1 style="text-align:center">Problem Statement</h1>
        <tr>
            <td>
                <ul>
                    <li>Last-mile delivery challenges in urban environments include traffic congestion, delays, and environmental impacts, which hinder efficient operations.</li>
                    <li>Existing solutions like rovers and drones face limitations in navigating rough terrain, stairs, and urban complexities, and have restricted operational ranges.</li>
                    <li>A comprehensive solution integrating the strengths of both rovers and drones is needed to address these challenges, ensuring adaptable, safe, and efficient deliveries.</li>
                </ul>
            </td>
        </tr>
    </table>
	<br>
	<hr>
	<table align=center width=850px>
		<center><h1>Modules</h1></center>
		<tr>
			<td> 
				<ul>
					<li><b>Rover</b>:  The rover is the physical vehicle or robot that is designed for autonomous ground navigation. It serves as the main component of the rover ecosystem and is responsible for carrying out various tasks and missions. The rover consists of several subsystems and components that work together to enable its operation and functionality.</li>
					<li><b>Subsystems of Rover</b>:</li>
                                        <li><b>Motor</b>: Motors provide the necessary propulsion for the rover to move. They generate rotational motion that drives the wheels or tracks of the rover.</li.
					<li><b>ESC (Electronic Speed Controller)</b>: ESCs control the speed and direction of the motors by regulating the power supply to them.</li>
					<li><b>Flight Controller</b>: The flight controller acts as the brain of the rover, responsible for processing sensor data, executing control algorithms, and generating commands to control the rover's movements. In the context of rovers, the flight controller, such as Pixhawk, is used as a central processing unit.</li>
					<li><b>Frame</b>: The frame refers to the physical structure or chassis of the rover that holds all the components together. It provides stability and protection to the internal components.</li>
					<li><b>Sensors</b>: Sensors play a crucial role in the rover's perception and navigation capabilities. They can include cameras, LiDAR, GPS, inertial measurement units (IMUs), and other environmental sensors. These sensors gather data about the rover's surroundings and provide valuable information for decision-making and navigation.</li>
						<figure align=center>
							<img style="width:500px" src="files/css/image/rplidar-a2-pixhawk.jpg"/>
							<figcaption align="center">Lidar and Pixhawk
							</figcaption>
						</figure>
					<br>
				<li> <b>Ground Control System</b>:</li>
                                        <li>The ground control system (GCS) is a vital part of the rover ecosystem, enabling remote control, monitoring, and communication with the rover. It consists of hardware and software components that allow operators or users to interact with the rover and oversee its operation.</li>
				        <li><b>Ground Control System Components</b>:</li>
                                        <li><b>Hardware</b>: The hardware components of the ground control system include devices such as laptops, tablets, smartphones, or dedicated ground control stations. These devices provide a user interface for operators to interact with the rover and monitor its status.</li>
					<li><b>Software</b>: The software component of the ground control system includes applications or programs that facilitate communication, mission planning, and monitoring of the rover. Examples of popular ground control software are Mission Planner (Windows) and QGroundControl (available for IOS, Linux, and Windows).</li>
						<figure align=center>
							<img style="width:500px" src="files/css/image//nvidia-jetson-nano-development-kit.jpg"/>
							<figcaption align="center">Jetson Nano
							</figcaption>
						</figure>
					<br>

				        <li><b>Communication Systems</b>:</li>
                                        <li>Communication systems are responsible for establishing a reliable connection between the rover and the ground control system. They enable real-time data transmission, command execution, and telemetry monitoring.</li>
				        <li><b>Communication System Components</b>:</li>
                                        <li><b>Hardware</b>: The hardware components of the communication system include telemetry systems and antennas. Telemetry systems establish a wireless link between the rover and the ground control system, allowing bidirectional data transmission. Antennas help in transmitting and receiving signals over the communication link.</li>
				        <li><b>Software</b>: The software component of the communication system involves protocols and communication frameworks that facilitate data exchange between the rover and the ground control system. MAVLink is a popular communication protocol used in the drone and rover ecosystem. It provides a lightweight and efficient means of communication between different components of the system.</li>
						<br><br>
							<figure align=center>
								<img align="center" style="width:400px" src="files/css/image/rover.png"/>
								<figcaption align="center">Telemetry System</figcaption>
							</figure>
					</li>
					<br><br>

				</ul>
			
			</td>
		</tr>
	</table>

	<br>

	
	<hr>
	<table align=center width=850px>
		<center><h1>Results</h1></center>
		<tr>
			<td>
				<ul>
					<li>Our advanced rover system boasts an impressive capability to accurately detect objects positioned ahead of it, facilitating intelligent decision-making for obstacle avoidance.</li> 
					<li>Leveraging this capability, it can dynamically maneuver towards the nearest path, be it on the left or right, ensuring seamless navigation in complex environments.</li>
					<li>Moreover, the rover diligently adheres to a predetermined list of waypoints, meticulously following its navigation path with precision and reliability.</li> 
					<li>By seamlessly integrating object detection, adaptive path selection, and waypoint-guided navigation, our rover consistently reaches its desired end goal, making it a highly professional and efficient solution for a wide range of applications.</li>
					<li>The rover "Agni" employs semantic segmentation as a key navigational tool to ensure adherence to the road while avoiding off-road areas like grass.</li>
					<li>This advanced technique involves labeling various segments of the road environment, where each label is assigned a unique numerical identifier.</li>
					<li>These identifiers are crucial for the rover's understanding and interpretation of its surroundings.</li> 
					<li>Consequently, Agni is able to autonomously navigate by processing these labels, distinguishing between different areas such as the road and grass, thereby facilitating effective and safe autonomous navigation.</li>
					<br>
					<figure style="text-align: center;">
                                             <img class="round" style="width:350px; display: block; margin: auto;" src="files/css/image/Screenshot_20230525_181311_Gallery (1).jpg"/>
                                             <figcaption><b>AGNI completing the navigation for its path trace and arriving to its end point</b></figcaption>

                                                 <br><br>
    
                                            <img class="round" style="width:350px; display: block; margin: auto;" src="files/css/image/Screenshot_20230525_181628_Gallery (1).jpg"/>
                                        </figure>
					<figcaption align="center"><b>AGNI driving autonomously at the UCI campus</b></figcaption>

					          <br><br>
					    <img class="round" style="width:350px; display: block; margin: auto;" src="files/css/image/Screenshot (42).png"/>
                                        </figure>
					<figcaption align="center"><b>AGNI tracing its path on the road and staying away from the grass</b></figcaption>

					           <br><br>
					
<div class="resource-list">
    <h2>Youtube Videos</h2>
    <ul>
        <li><a href="https://www.youtube.com/watch?v=jTv6dk9j2JI" target="_blank">20 waypoints with object avoidance</a></li>
	<li><a href="https://www.youtube.com/watch?v=JtF-74tIR2g" target="_blank"> Semantic Segmentation</a></li>    
        <li><a href="https://www.youtube.com/watch?v=-MjjNYNSlf0" target="_blank">Wave point attempt</a></li>
        <li><a href="https://www.youtube.com/shorts/ye08_Nmhqas" target="_blank">Object Avoidance initial</a></li>
        <li><a href="https://www.youtube.com/watch?v=VVnbwAQF_hk&t=1s"_blank">Object Avoidance</a></li>
        <li><a href="https://www.youtube.com/shorts/3u-YGskfcaE" target="_blank">Object detection attempt</a></li>
        <li><a href="https://www.youtube.com/shorts/kCvzaAcpXC0" target="_blank">Object detection</a></li>
        <li><a href="https://www.youtube.com/shorts/CeqQycyqet4" target="_blank">Rover Movement</a></li>
	    <li><a href="https://www.youtube.com/watch?v=iRgux_9Lnx4" target="_blank"> Fail Attempt</a></li>
	    <li><a href="https://www.youtube.com/shorts/OGabWa8hgZo" target="_blank"> Failed Attempt</a></li>
	    <li><a href="https://www.youtube.com/shorts/aZOSRmImusE" target="_blank"> Dancing Rover</a></li>
        <li><a href="https://www.youtube.com/shorts/4FKzNsXotM0" target="_blank"> Random Movements</a></li>
    </ul>
</div>
				</ul>
			
			</td>
		</tr>
	</table>

	<br>


	<!-- <center> <h3> Distance between Adjacent Buildings </h3>
	<img class="round" style="width:1000px" src="assets/images/DistanceModule.png"/>
	<p>This module provide us the distance between two adjacent buildings. We sampled the images from the videos captured by UAV and perform panoptic segmentation using state-of-art deep learning model, eliminating vegetation (like trees) from the images. The masked images are then fed to a state-of-the art image-based 3D reconstruction library which outputs a dense 3D point cloud. We then apply RANSAC for fitting planes between the segmented structural point cloud. Further, the points are sampled on these planes to calculate the distance between the adjacent buildings at different locations.</p>
	</center>
	<br> -->


	<!-- <center> <h3> Results: Distance between Adjacent Buildings </h3>
	<img class="round" style="width:800px" src="assets/images/Results-DistanceModule-1.png"/>
	<p> Sub-figures (a), (b) and (c) and (d), (e) and (f) represent the implementation of plane fitting using piecewise-RANSAC in different views for two subject buildings.</p>
	
	</center>
	<br> -->




	<!-- <center> <h3> Plan Shape and Roof Area Estimation </h3>
	<img class="round" style="width:1000px" src="assets/images/PlanShape&RoofareaEstimation.png"/>
	<p>This module provides information regarding the shape and roof area of the building. We segment the roof using a state-of-the-art semantic segmentation deep learning model. We also subjected the input images to a pre-processing module that removes distortions from the wide-angle images. Data augmentation was used to increase the robustness and performance. Roof Area was calculated using the focal length of the camera, the height of the drone from the roof and the segmented mask area in pixels.
</p>
	</center>
	<br>



	<center> <h3> Results: Plan Shape and Roof Area Estimation </h3>
	<img class="round" style="width:800px" src="assets/images/Results-PlanShape&RoofareaEstimation-1.png"/>
	<p>This figure represents the roof segmentation results for 4 subject buildings.</p>
	
	</center>
	<br>


	<center> <h3> Roof Layout Estimation </h3>
	<img class="round" style="width:1000px" src="assets/images/RoofLaoutEstimation.png"/>
	<p>This module provides information about the roof layout. Since it is not possible to capture the whole roof in a single frame specially in the case of large sized buildings, we perform large scale image stitching of partially visible roofs followed by NSE detection and roof segmentation.

</p>
	</center>
	<br> -->



	<!-- <center> <h3> Results: Roof Layout Estimation </h3>
	<img class="round" style="width:800px" src="assets/images/imagestitchingoutput.jpeg"/>
	<p>Stitched Image</p>
	<img class="round" style="width:800px" src="assets/images/roofmask.png"/>
	<p>Roof Mask</p>
	<img class="round" style="width:800px" src="assets/images/objectmask.png"/>
	<p>Object Mask</p>
	
	</center>
	<br> -->




<!--

	<center> <h1> Resources </h1>
	<table width="100%" style="margin: 20pt auto; text-align: center;">
	      <tr>
				<td width="33%" valign="middle">
				    <center>
					<a href="https://github.com/atmacvit/meronymnet" target="_blank"
					   class="imageLink"><img src="./resources/Octocat.png" ,=, width="75%" /></a><br /><br />
					<a href="https://github.com/atmacvit/meronymnet" target="_blank">Code</a>
				    </center>
				</td>
				<td width="33%" valign="middle">
				    <center>
					<a href="https://drive.google.com/file/d/1NnY4tcV1wnlSWMzT_Ae6hH6v5l8GCIrX/view?usp=sharing" target="_blank"
					   class="imageLink"><img src="./resources/Paper_crop.png" ,=, width="75%" /></a><br /><br />
					<a href="https://drive.google.com/file/d/1NnY4tcV1wnlSWMzT_Ae6hH6v5l8GCIrX/view?usp=sharing" target="_blank">Paper</a>
				    </center>

				</td>


			       <td width="33%" valign="middle">
				    <center>
					<a href="" target="_blank"
					   class="imageLink"><img src="./resources/Supp_crop.png" ,=, width="75%" /></a><br /><br />
					<a href="" target="_blank">Supplementary</a>
				    </center>
				</td>
	      </tr>
    	</table>
	</center>
	<br>

	<table align=center width=600px>
		<tr>
			<td><span style="font-size:14pt"><center>
				<a href="./resources/bibtex.txt">[Bibtex]</a>
			</center></td>
		</tr>
	</table>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br> -->
<hr>
<center> <h1> Contact </h1>
	<p>If you have any questions, please reach out to any of the above mentioned authors.</p>
	</center>
<script>
        function toggleContent(contentId) {
            var content = document.getElementById(contentId);
            if (content.style.display === "none") {
                content.style.display = "block";
            } else {
                content.style.display = "none";
            }
        }
    </script>
</body>
</html>
